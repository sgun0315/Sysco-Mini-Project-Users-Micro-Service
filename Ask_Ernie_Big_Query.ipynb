{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNEtVJmY5kYiRY7dbcubVfg",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/sgun0315/Sysco-Mini-Project-Users-Micro-Service/blob/master/Ask_Ernie_Big_Query.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "QiFflLpBbWP5",
        "outputId": "18ba10cf-9ea8-4bdb-deb5-8b6f41a3a020"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: google-api-core in /usr/local/lib/python3.11/dist-packages (2.24.2)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0.0,>=1.56.2 in /usr/local/lib/python3.11/dist-packages (from google-api-core) (1.70.0)\n",
            "Requirement already satisfied: protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<7.0.0,>=3.19.5 in /usr/local/lib/python3.11/dist-packages (from google-api-core) (5.29.4)\n",
            "Requirement already satisfied: proto-plus<2.0.0,>=1.22.3 in /usr/local/lib/python3.11/dist-packages (from google-api-core) (1.26.1)\n",
            "Requirement already satisfied: google-auth<3.0.0,>=2.14.1 in /usr/local/lib/python3.11/dist-packages (from google-api-core) (2.38.0)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.18.0 in /usr/local/lib/python3.11/dist-packages (from google-api-core) (2.32.3)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from google-auth<3.0.0,>=2.14.1->google-api-core) (5.5.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from google-auth<3.0.0,>=2.14.1->google-api-core) (0.4.2)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.11/dist-packages (from google-auth<3.0.0,>=2.14.1->google-api-core) (4.9.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.18.0->google-api-core) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.18.0->google-api-core) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.18.0->google-api-core) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.18.0->google-api-core) (2025.4.26)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.6.1 in /usr/local/lib/python3.11/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3.0.0,>=2.14.1->google-api-core) (0.6.1)\n",
            "Requirement already satisfied: google-cloud-bigquery in /usr/local/lib/python3.11/dist-packages (3.32.0)\n",
            "Requirement already satisfied: google-api-core<3.0.0,>=2.11.1 in /usr/local/lib/python3.11/dist-packages (from google-api-core[grpc]<3.0.0,>=2.11.1->google-cloud-bigquery) (2.24.2)\n",
            "Requirement already satisfied: google-auth<3.0.0,>=2.14.1 in /usr/local/lib/python3.11/dist-packages (from google-cloud-bigquery) (2.38.0)\n",
            "Requirement already satisfied: google-cloud-core<3.0.0,>=2.4.1 in /usr/local/lib/python3.11/dist-packages (from google-cloud-bigquery) (2.4.3)\n",
            "Requirement already satisfied: google-resumable-media<3.0.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from google-cloud-bigquery) (2.7.2)\n",
            "Requirement already satisfied: packaging>=24.2.0 in /usr/local/lib/python3.11/dist-packages (from google-cloud-bigquery) (24.2)\n",
            "Requirement already satisfied: python-dateutil<3.0.0,>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from google-cloud-bigquery) (2.9.0.post0)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.21.0 in /usr/local/lib/python3.11/dist-packages (from google-cloud-bigquery) (2.32.3)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0.0,>=1.56.2 in /usr/local/lib/python3.11/dist-packages (from google-api-core<3.0.0,>=2.11.1->google-api-core[grpc]<3.0.0,>=2.11.1->google-cloud-bigquery) (1.70.0)\n",
            "Requirement already satisfied: protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<7.0.0,>=3.19.5 in /usr/local/lib/python3.11/dist-packages (from google-api-core<3.0.0,>=2.11.1->google-api-core[grpc]<3.0.0,>=2.11.1->google-cloud-bigquery) (5.29.4)\n",
            "Requirement already satisfied: proto-plus<2.0.0,>=1.22.3 in /usr/local/lib/python3.11/dist-packages (from google-api-core<3.0.0,>=2.11.1->google-api-core[grpc]<3.0.0,>=2.11.1->google-cloud-bigquery) (1.26.1)\n",
            "Requirement already satisfied: grpcio<2.0dev,>=1.33.2 in /usr/local/lib/python3.11/dist-packages (from google-api-core[grpc]<3.0.0,>=2.11.1->google-cloud-bigquery) (1.71.0)\n",
            "Requirement already satisfied: grpcio-status<2.0.dev0,>=1.33.2 in /usr/local/lib/python3.11/dist-packages (from google-api-core[grpc]<3.0.0,>=2.11.1->google-cloud-bigquery) (1.71.0)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from google-auth<3.0.0,>=2.14.1->google-cloud-bigquery) (5.5.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from google-auth<3.0.0,>=2.14.1->google-cloud-bigquery) (0.4.2)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.11/dist-packages (from google-auth<3.0.0,>=2.14.1->google-cloud-bigquery) (4.9.1)\n",
            "Requirement already satisfied: google-crc32c<2.0dev,>=1.0 in /usr/local/lib/python3.11/dist-packages (from google-resumable-media<3.0.0,>=2.0.0->google-cloud-bigquery) (1.7.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil<3.0.0,>=2.8.2->google-cloud-bigquery) (1.17.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.21.0->google-cloud-bigquery) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.21.0->google-cloud-bigquery) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.21.0->google-cloud-bigquery) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3.0.0,>=2.21.0->google-cloud-bigquery) (2025.4.26)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.6.1 in /usr/local/lib/python3.11/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3.0.0,>=2.14.1->google-cloud-bigquery) (0.6.1)\n"
          ]
        }
      ],
      "source": [
        "%pip install google-api-core\n",
        "%pip install --upgrade google-cloud-bigquery"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import auth\n",
        "auth.authenticate_user()"
      ],
      "metadata": {
        "id": "pdgkWvE-zkIE"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import vertexai\n",
        "\n",
        "project_id = \"syy-dom-np-fd67\"\n",
        "region = \"us-central1\"\n",
        "vertexai.init(project=project_id, location=region)"
      ],
      "metadata": {
        "id": "raPOEOOszo-p"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "BQ_DATASET_NAME = \"scm_chatbot_datastore_dev\"\n",
        "BQ_KNOWLEDGE_DATASET_NAME = \"chatbot_knowledge_datastore_dev\"\n",
        "BQ_SITE_DETAILS_TABLE_NAME = \"site_region_market\"\n",
        "BQ_TABLE_SCHEMA_KNOWLEDGE_TABLE_NAME = \"table_details\"\n",
        "BQ_COLUMN_SCHEMA_KNOWLEDGE_TABLE_NAME = \"table_column_details\"\n",
        "BQ_BUSINESS_KNOWLEDGE_TABLE_NAME = \"business_rules\"\n",
        "BQ_HISTORY_SQL_TABLE_NAME = \"known_good_sqls\"\n",
        "\n",
        "APPLICATION_NAME = \"Merchandising\"\n",
        "GOOGLE_CLOUD_QUOTA_PROJECT = \"syy-dom-np-fd67\"\n",
        "GOOGLE_CLOUD_QUOTA_PROJECT_REGION = \"us-central1\""
      ],
      "metadata": {
        "id": "AEp-AD6XbaJv"
      },
      "execution_count": 152,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import logging\n",
        "from typing import Literal\n",
        "\n",
        "from google.api_core.exceptions import GoogleAPICallError, BadRequest, ServiceUnavailable\n",
        "from google.cloud import bigquery\n",
        "\n",
        "logger = logging.getLogger(__name__)\n",
        "\n",
        "class BQConnector:\n",
        "    \"\"\"Big Query Connector Implementation.\"\"\"\n",
        "\n",
        "    def __init__(self, source, project_id, region):\n",
        "        self.source = source\n",
        "\n",
        "        self.project_id = project_id\n",
        "        self.region = region\n",
        "        self.dataset_name = BQ_DATASET_NAME\n",
        "        self.chatbot_knowledge_dataset = BQ_KNOWLEDGE_DATASET_NAME\n",
        "\n",
        "        self._client = bigquery.Client(project=project_id, location=region)\n",
        "\n",
        "    def execute_query(self, query):\n",
        "        \"\"\"Execute the given query and return the result in dataframe\"\"\"\n",
        "        try:\n",
        "            return self._client.query_and_wait(query).to_dataframe()\n",
        "        except (TimeoutError, GoogleAPICallError, BadRequest, ServiceUnavailable) as e:\n",
        "            logger.error(\"Error Executing Query: %s\", e)\n",
        "            raise ResourceConnectionError(f\"Error executing query: {e}\", service=\"BigQuery\", errors=e) from e\n",
        "\n",
        "    def retrieve_site_details(self):\n",
        "        site_details_table_name = BQ_SITE_DETAILS_TABLE_NAME\n",
        "        site_details_query = f\"\"\"\n",
        "            SELECT site_id, site_name, region_name, market_name\n",
        "            FROM `{self.project_id}.{self.dataset_name}.{site_details_table_name}`\n",
        "        \"\"\"\n",
        "\n",
        "        results = self.execute_query(site_details_query)\n",
        "        site_details_list = []\n",
        "        for index, row in results.iterrows():\n",
        "            site_details_list.append({\n",
        "                \"site_id\": row[\"site_id\"],\n",
        "                \"site_name\": row[\"site_name\"],\n",
        "                \"region_name\": row[\"region_name\"],\n",
        "                \"market_name\": row[\"market_name\"]\n",
        "            })\n",
        "\n",
        "        return site_details_list\n",
        "\n",
        "    def retrieve_matches(\n",
        "            self,\n",
        "            mode: Literal[\"table\", \"column\", \"example\", \"business_rule\"],\n",
        "            qe,\n",
        "            similarity_threshold,\n",
        "            limit,\n",
        "    ):\n",
        "        \"\"\"This function retrieves the most similar table_schema and column_schema.\n",
        "\n",
        "        Arguments:\n",
        "            mode {Literal['table', 'column', or 'example']} -- Mode for the retriever.\n",
        "            qe {str} -- User Question Embedding\n",
        "            similarity_threshold {int} -- Similarity Threshold to filter results\n",
        "            limit {int} -- Query result set limit\n",
        "\n",
        "        Return:\n",
        "            result {pd.DataFrame} -- Result set from DB\n",
        "        \"\"\"\n",
        "        logger.info(\"Searching %s. Threshold: %s. Limit: %s\", mode, similarity_threshold, limit)\n",
        "\n",
        "        embeddings_retrieval_sql = \"\"\"\n",
        "        (select base.content as content\n",
        "        from vector_search(\n",
        "                    TABLE `{}`,\n",
        "                    \"embedding\",\n",
        "                    (SELECT {} as qe),\n",
        "                    top_k=> {},\n",
        "                    distance_type=>\"DOT_PRODUCT\"\n",
        "        )\n",
        "        where (1 - distance > {}) and base.source_type = \"{}\")\n",
        "        \"\"\"\n",
        "        search_result_txt = \"\"\n",
        "\n",
        "        if mode == \"table\":\n",
        "            table_name = BQ_TABLE_SCHEMA_KNOWLEDGE_TABLE_NAME\n",
        "            search_result_txt = \"Schema(values):\"\n",
        "\n",
        "        elif mode == \"column\":\n",
        "            table_name = BQ_COLUMN_SCHEMA_KNOWLEDGE_TABLE_NAME\n",
        "            search_result_txt = \"Column name(type):\"\n",
        "\n",
        "        elif mode == \"business_rule\":\n",
        "            table_name = BQ_BUSINESS_KNOWLEDGE_TABLE_NAME\n",
        "            embeddings_retrieval_sql = \"\"\"(\n",
        "                select base.ruleset as content, base.content as identifier, (1 - distance) AS similarity\n",
        "                from vector_search (\n",
        "                    TABLE `{}`,\n",
        "                    \"embedding\",\n",
        "                    (select {} as qe),\n",
        "                    top_k=> {},\n",
        "                    distance_type=>\"COSINE\"\n",
        "                )\n",
        "                where (1 - distance > {}) and base.source_type = \"{}\")\n",
        "            \"\"\"\n",
        "\n",
        "        elif mode == \"example\":\n",
        "            table_name = BQ_HISTORY_SQL_TABLE_NAME\n",
        "            embeddings_retrieval_sql = \"\"\"(\n",
        "                select base.intent as user_question, base.template_sql as generated_sql\n",
        "                from vector_search ( TABLE `{}`, \"embedding\", (select {} as qe), top_k=> {}, distance_type=>\"COSINE\")\n",
        "                where (1 - distance > {}) and base.source_type = \"{}\")\n",
        "            \"\"\"\n",
        "        else:\n",
        "            raise ValueError(\"No valid mode. Must be either table, column, or example\")\n",
        "\n",
        "        embeddings_retrieval_sql = embeddings_retrieval_sql.format(\n",
        "            f\"{self.project_id}.{self.chatbot_knowledge_dataset}.{table_name}\",\n",
        "            qe,\n",
        "            limit,\n",
        "            similarity_threshold,\n",
        "            self.source,\n",
        "        )\n",
        "        logger.debug(embeddings_retrieval_sql)\n",
        "\n",
        "        results = self.execute_query(embeddings_retrieval_sql)\n",
        "\n",
        "        # CHECK RESULTS\n",
        "        if len(results) == 0:\n",
        "            logger.info(\"Did not find any results. Adjust the query parameters.\")\n",
        "            return search_result_txt\n",
        "\n",
        "        if mode in {\"table\", \"column\"}:\n",
        "            for _, r in results.iterrows():\n",
        "                search_result_txt = search_result_txt + r[\"content\"] + \"\\n\"\n",
        "\n",
        "        elif mode == \"business_rule\":\n",
        "            for _, r in results.iterrows():\n",
        "                rule = r[\"content\"]\n",
        "                score = round(r[\"similarity\"], 3)\n",
        "                search_result_txt += f\"{rule} (score: {score})\\n\"\n",
        "\n",
        "        elif mode == \"example\":\n",
        "            search_result_txt = \"\"\n",
        "            for _, r in results.iterrows():\n",
        "                example_user_question = r[\"user_question\"]\n",
        "                example_sql = r[\"generated_sql\"]\n",
        "                search_result_txt = (\n",
        "                        search_result_txt\n",
        "                        + \"\\n Example_question: \"\n",
        "                        + example_user_question\n",
        "                        + \" | Example_SQL: \"\n",
        "                        + example_sql.replace('\"', \"'\")\n",
        "                        + \"\\n\"\n",
        "                )\n",
        "        # Remove additional spaces & whitespaces\n",
        "        search_result_txt = search_result_txt.strip()\n",
        "        logger.debug(\"Mode: %s Semantic Search Result: \\n%s\", mode, search_result_txt)\n",
        "        return search_result_txt"
      ],
      "metadata": {
        "id": "9lQho-vxbgqq"
      },
      "execution_count": 214,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import logging\n",
        "from typing import Optional, List, Literal\n",
        "\n",
        "from vertexai.language_models import TextEmbeddingModel, TextEmbeddingInput\n",
        "\n",
        "logger = logging.getLogger(__name__)\n",
        "\n",
        "\n",
        "class EmbedderAgent:\n",
        "    \"\"\"Embedder Agent Implementation\"\"\"\n",
        "\n",
        "    agent_type: str = \"EmbedderAgent\"\n",
        "\n",
        "    def __init__(self, embeddings_model: str = \"text-embedding-004\"):\n",
        "        self.embeddings_model = embeddings_model\n",
        "        self.model = TextEmbeddingModel.from_pretrained(model_name=embeddings_model)\n",
        "        logger.info(\"Embedder Agent Initialized in the given project.\")\n",
        "\n",
        "    async def create(\n",
        "            self,\n",
        "            questions,\n",
        "            task: Literal[\"RETRIEVAL_QUERY\", \"RETRIEVAL_DOCUMENT\", \"SEMANTIC_SIMILARITY\"] = \"SEMANTIC_SIMILARITY\",\n",
        "            dimensionality: Optional[int] = 768,\n",
        "    ) -> List[List[float]]:\n",
        "        \"\"\"Text embedding with a Large Language Model.\"\"\"\n",
        "\n",
        "        inputs = [TextEmbeddingInput(text, task) for text in questions]\n",
        "        kwargs = {\"output_dimensionality\": dimensionality}\n",
        "        embeddings = await self.model.get_embeddings_async(inputs, **kwargs)\n",
        "        return [embedding.values for embedding in embeddings]"
      ],
      "metadata": {
        "id": "gefoXUbQe6iz"
      },
      "execution_count": 215,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "VECTOR_BUSINESS_RULES_MATCH_SCORE_MATCHES = 0.6\n",
        "\n",
        "async def get_embeddings_for_text(text):\n",
        "    \"\"\"Get Text Embeddings from Model\"\"\"\n",
        "    embedder = EmbedderAgent(embeddings_model='text-embedding-004')\n",
        "    embeddings = await embedder.create([text])\n",
        "    return embeddings[0]"
      ],
      "metadata": {
        "id": "jAJHrIG5fe2e"
      },
      "execution_count": 223,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "bq_connector = BQConnector(\n",
        "    APPLICATION_NAME,\n",
        "    GOOGLE_CLOUD_QUOTA_PROJECT,\n",
        "    GOOGLE_CLOUD_QUOTA_PROJECT_REGION\n",
        ")"
      ],
      "metadata": {
        "id": "ov_ycpYNqYAs"
      },
      "execution_count": 224,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "async def get_business_rule(message):\n",
        "  embedded_question = await get_embeddings_for_text(message)\n",
        "\n",
        "\n",
        "  return bq_connector.retrieve_matches(\n",
        "      \"business_rule\",\n",
        "      embedded_question,\n",
        "      VECTOR_BUSINESS_RULES_MATCH_SCORE_MATCHES,\n",
        "      5\n",
        "  )\n"
      ],
      "metadata": {
        "id": "Am45fT82bjIl"
      },
      "execution_count": 225,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "queries = [\n",
        "    [\"Show me 3 late POs at site 048\", \"Late PO\"],\n",
        "    [\"How many late POs at site 048\", \"Late PO\"],\n",
        "    [\"Show me 10 late POs at site 048\", \"Late PO\"],\n",
        "    [\"SHow me first 4 late POs at site 002\", \"Late PO\"],\n",
        "    [\"Show me the top 4 late purchase orders at site 002\", \"Late PO\"],\n",
        "    [\"How many late pos at site 002\", \"Late PO\"],\n",
        "    [\"How many late pos at 048, 002\", \"Late PO\"],\n",
        "    [\"How many late PO's do I have at site 048\", \"Late PO\"],\n",
        "    [\"What's the current tally of late POs at site 048\", \"Late PO\"],\n",
        "    [\"How many late PO's do I have at market south\", \"Late PO\"],\n",
        "    [\"How many late PO's do I have at region carolinas\", \"Late PO\"],\n",
        "    [\"How many late PO's do I have at site sysco charlotte\", \"Late PO\"],\n",
        "    [\"Is the above PO a late PO?\", \"Late PO\"],\n",
        "    [\"How many late POs are there in that site\", \"Late PO\"],\n",
        "    [\"How many late POs do I have in that site?\", \"Late PO\"],\n",
        "    [\"Give me a list of very old POs (older than 2 months) which I need to clean up at site 163\", \"PO With Older Than Given Month\"],\n",
        "    [\"I'm looking for a list of aged POs (older than 2 months) that require cleanup in site 048.\", \"PO With Older Than Given Month\"],\n",
        "    [\"Give me a list of very old POs (older than 2 months) which I need to clean up market south\", \"PO With Older Than Given Month\"],\n",
        "    [\"Give me a list of very old POs (older than 2 months) which I need to clean up region carolinas\", \"PO With Older Than Given Month\"],\n",
        "    [\"Give me a list of very old POs (older than 2 months) which I need to clean up at site Charlotte\", \"PO With Older Than Given Month\"],\n",
        "    [\"How many unscheduled PO's? at site 164?\", \"Unscheduled PO\"],\n",
        "    [\"Do we have any unscheduled POs in site 164, and if so, how many?\", \"Unscheduled PO\"],\n",
        "    [\"How many unscheduled PO's? in market south?\", \"Unscheduled PO\"],\n",
        "    [\"How many unscheduled PO's? at in region south\", \"Unscheduled PO\"],\n",
        "    [\"How many unscheduled PO's? at site Raleigh\", \"Unscheduled PO\"],\n",
        "    [\"How many unscheduled POs are there in site 002?\", \"Unscheduled PO\"],\n",
        "    [\"How many unscheduled POs do I have in site 002?\", \"Unscheduled PO\"],\n",
        "    [\"Show me POs received short of total quantity. Threshold hold of 5 cases or more at site 002\", \"Shorted PO\"],\n",
        "    [\"Display PO's where the received quantity falls short of the total, with a minimum of 5 cases or more at site 048.\", \"Shorted PO\"],\n",
        "    [\"Show me POs received short of total quantity. Threshold hold of 5 cases or more in south\", \"Shorted PO\"],\n",
        "    [\"Show me POs received short of total quantity. Threshold hold of 5 cases or more in region carolinas\", \"Shorted PO\"],\n",
        "    [\"Show me POs received short of total quantity. Threshold hold of 5 cases or more at site south\", \"Shorted PO\"],\n",
        "    [\"Show me PO's received short of total qty. Threshold hold of 5 cases or more\", \"Shorted PO\"],\n",
        "    [\"Show POs received short of total quantity by 5+ Cases at Site 048\", \"Shorted PO\"],\n",
        "    [\"Give me a list of POs which are stuck in recommended status at site 164\", \"PO With RECOMMENDED Status\"],\n",
        "    [\"Could you share the purchase orders that remain in the 'recommended' status at site 164?\", \"PO With RECOMMENDED Status\"],\n",
        "    [\"Give me a list of POs which are stuck in recommended status in market south\", \"PO With RECOMMENDED Status\"],\n",
        "    [\"Give me a list of POs which are stuck in recommended status in region carolinas\", \"PO With RECOMMENDED Status\"],\n",
        "    [\"Give me a list of POs which are stuck in recommended status at site <site name>\", \"PO With RECOMMENDED Status\"],\n",
        "    [\"How many unscheduled POs are that site?\", \"Unscheduled PO\"],\n",
        "    [\"Is the above PO is stucked in recommended state?\", \"PO With RECOMMENDED Status\"],\n",
        "    [\"How many POs do I have stuck in recommended state in that site?\", \"PO With RECOMMENDED Status\"],\n",
        "    [\"PO's that have a scheduled appointment that is in the past at site 002\", \"Scheduled PO\"],\n",
        "    [\"Are there POs with scheduled appointments that are in the past at site 002?\", \"Scheduled PO\"],\n",
        "    [\"PO's that have a scheduled appointment that is in the past market south\", \"Scheduled PO\"],\n",
        "    [\"PO's that have a scheduled appointment that is in the past region carolinas\", \"Scheduled PO\"],\n",
        "    [\"PO's that have a scheduled appointment that is in the past at site Carlotte\", \"Scheduled PO\"],\n",
        "    [\"How many POs do not have an Order control number at site 002\", \"PO Without OC\"],\n",
        "    [\"What is the number of POs that haven't been assigned an OC number at site 048?\", \"PO Without OC\"],\n",
        "    [\"How many POs do not have an OC# in market south\", \"PO Without OC\"],\n",
        "    [\"How many POs do not have an OC# in region carolinas\", \"PO Without OC\"],\n",
        "    [\"How many POs do not have an OC# at site charlotte\", \"PO Without OC\"],\n",
        "    [\"How many Purchase orders do not have an OC number at site gulf coast\", \"PO Without OC\"],\n",
        "    [\"How many POs do not have an OC# at site 164\", \"PO Without OC\"],\n",
        "    [\"Is the PO 10973040 from site 002?\", \"Uncategorized\"],\n",
        "    [\"How many POs do I have in site 164\", \"Uncategorized\"],\n",
        "]\n"
      ],
      "metadata": {
        "id": "yTHE5trtbsds"
      },
      "execution_count": 226,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "business_rules = {\n",
        "    \"Late PO\": \"anticipated receipt date should be before than today. purchase order type should be 'REGULAR' and purchase order primary status should be 'OPEN' and purchase order secondary status either 'SCHEDULED' OR 'ACCEPTED'\",\n",
        "    \"Unscheduled PO\": \"purchase order primary status should be 'OPEN' and purchase order secondary status should be 'ACCEPTED' and purchase order type should be 'REGULAR' and vendor id should not be equals to '359958' or '495149'. no need to consider about order control number or scheduled purchase order receipt timestamp\",\n",
        "    \"Shorted PO\": \"purchase order primary status should be 'CLOSED' and if the question includes a threshold, minimum value, then total vendor short quantity should be greater than or equal to that value. If no such value is mentioned compare with 0. threshold is a non negative value. Do not use TOTAL_RECEIVED_CASES or any other fields in the filtering logic.\",\n",
        "    \"PO With RECOMMENDED Status\": \"purchase order primary status should be 'RECOMMENDED' and purchase order secondary status should be 'RECOMMENDED' and replenishment system should be 'DPR'\",\n",
        "    \"PO With Older Than Given Month\": \"(anticipated receipt date + given time interval or date) should be older than today date and purchase order primary status equals to 'OPEN' and purchase order secondary status not equals to 'PARTIALLY_RECEIVED'\",\n",
        "    \"Scheduled PO\": \"date of scheduled purchase order receipt timestamp should be before today's date. purchase order primary status should be 'OPEN' and purchase order secondary status should be 'SCHEDULED'\",\n",
        "    \"PO Without OC\": \"order control number is null and purchase order primary status should be 'OPEN'.\",\n",
        "    \"Uncategorized\": \"Uncategorized\"\n",
        "}"
      ],
      "metadata": {
        "id": "jZRJQ-tjrcRi"
      },
      "execution_count": 227,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "async def check_query(query_with_category):\n",
        "    query = query_with_category[0]\n",
        "    category = query_with_category[1]\n",
        "    business_rule = await get_business_rule(query)\n",
        "\n",
        "    if business_rules[category] == business_rule:\n",
        "        print(\"\\033[92mPASSED\\033[0m\")\n",
        "    else:\n",
        "        print(\"\\033[91mFAILED\\033[0m\")\n",
        "        print(f\"Expected: {business_rules[category]}\")\n",
        "        print(f\"Actual: {business_rule}\")\n",
        "    print(\"\\n\")"
      ],
      "metadata": {
        "id": "dDhlnU5jyHsb"
      },
      "execution_count": 228,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "await check_query([\"Show me the top 4 late Purchase Orders at site 002\", \"Late PO\"],)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nK-QEVpc1_ox",
        "outputId": "54a92759-0012-474b-ed94-8c094d01e62c"
      },
      "execution_count": 232,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[91mFAILED\u001b[0m\n",
            "Expected: anticipated receipt date should be before than today. purchase order type should be 'REGULAR' and purchase order primary status should be 'OPEN' and purchase order secondary status either 'SCHEDULED' OR 'ACCEPTED'\n",
            "Actual: (anticipated receipt date + given time interval or date) should be older than today date and purchase order primary status equals to 'OPEN' and purchase order secondary status not equals to 'PARTIALLY_RECEIVED' (score: 0.764)\n",
            "anticipated receipt date should be before than today. purchase order type should be 'REGULAR' and purchase order primary status should be 'OPEN' and purchase order secondary status either 'SCHEDULED' OR 'ACCEPTED' (score: 0.739)\n",
            "date of scheduled purchase order receipt timestamp should be before today's date. purchase order primary status should be 'OPEN' and purchase order secondary status should be 'SCHEDULED' (score: 0.698)\n",
            "purchase order primary status should be 'CLOSED' and if the question includes a threshold, minimum value, then total vendor short quantity should be greater than or equal to that value. If no such value is mentioned compare with 0. threshold is a non negative value. Do not use TOTAL_RECEIVED_CASES or any other fields in the filtering logic. (score: 0.688)\n",
            "purchase order primary status should be 'CLOSED' and if {threshold} is given in the question, then total vendor short quantity should be lesser than or equal to the negative value of the given {threshold}. If {threshold} is not given then compare with zero. {threshold} is a non negative value (score: 0.686)\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for query_with_category in queries:\n",
        "    await check_query(query_with_category)\n"
      ],
      "metadata": {
        "collapsed": true,
        "id": "SzIYXM4trEsK",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "e1d51fa0-ab2c-4bd5-f07c-fa0db948a446"
      },
      "execution_count": 230,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[91mFAILED\u001b[0m\n",
            "Expected: anticipated receipt date should be before than today. purchase order type should be 'REGULAR' and purchase order primary status should be 'OPEN' and purchase order secondary status either 'SCHEDULED' OR 'ACCEPTED'\n",
            "Actual: anticipated receipt date should be before than today. purchase order type should be 'REGULAR' and purchase order primary status should be 'OPEN' and purchase order secondary status either 'SCHEDULED' OR 'ACCEPTED' (score: 0.711)\n",
            "(anticipated receipt date + given time interval or date) should be older than today date and purchase order primary status equals to 'OPEN' and purchase order secondary status not equals to 'PARTIALLY_RECEIVED' (score: 0.667)\n",
            "date of scheduled purchase order receipt timestamp should be before today's date. purchase order primary status should be 'OPEN' and purchase order secondary status should be 'SCHEDULED' (score: 0.658)\n",
            "purchase order primary status should be 'CLOSED' and if {threshold} is given in the question, then total vendor short quantity should be lesser than or equal to the negative value of the given {threshold}. If {threshold} is not given then compare with zero. {threshold} is a non negative value (score: 0.64)\n",
            "purchase order primary status should be 'CLOSED' and if the question includes a threshold, minimum value, then total vendor short quantity should be greater than or equal to that value. If no such value is mentioned compare with 0. threshold is a non negative value. Do not use TOTAL_RECEIVED_CASES or any other fields in the filtering logic. (score: 0.636)\n",
            "\n",
            "\n",
            "\u001b[91mFAILED\u001b[0m\n",
            "Expected: anticipated receipt date should be before than today. purchase order type should be 'REGULAR' and purchase order primary status should be 'OPEN' and purchase order secondary status either 'SCHEDULED' OR 'ACCEPTED'\n",
            "Actual: anticipated receipt date should be before than today. purchase order type should be 'REGULAR' and purchase order primary status should be 'OPEN' and purchase order secondary status either 'SCHEDULED' OR 'ACCEPTED' (score: 0.707)\n",
            "purchase order primary status should be 'CLOSED' and if {threshold} is given in the question, then total vendor short quantity should be lesser than or equal to the negative value of the given {threshold}. If {threshold} is not given then compare with zero. {threshold} is a non negative value (score: 0.644)\n",
            "purchase order primary status should be 'CLOSED' and if the question includes a threshold, minimum value, then total vendor short quantity should be greater than or equal to that value. If no such value is mentioned compare with 0. threshold is a non negative value. Do not use TOTAL_RECEIVED_CASES or any other fields in the filtering logic. (score: 0.641)\n",
            "(anticipated receipt date + given time interval or date) should be older than today date and purchase order primary status equals to 'OPEN' and purchase order secondary status not equals to 'PARTIALLY_RECEIVED' (score: 0.636)\n",
            "date of scheduled purchase order receipt timestamp should be before today's date. purchase order primary status should be 'OPEN' and purchase order secondary status should be 'SCHEDULED' (score: 0.619)\n",
            "\n",
            "\n",
            "\u001b[91mFAILED\u001b[0m\n",
            "Expected: anticipated receipt date should be before than today. purchase order type should be 'REGULAR' and purchase order primary status should be 'OPEN' and purchase order secondary status either 'SCHEDULED' OR 'ACCEPTED'\n",
            "Actual: anticipated receipt date should be before than today. purchase order type should be 'REGULAR' and purchase order primary status should be 'OPEN' and purchase order secondary status either 'SCHEDULED' OR 'ACCEPTED' (score: 0.698)\n",
            "(anticipated receipt date + given time interval or date) should be older than today date and purchase order primary status equals to 'OPEN' and purchase order secondary status not equals to 'PARTIALLY_RECEIVED' (score: 0.672)\n",
            "date of scheduled purchase order receipt timestamp should be before today's date. purchase order primary status should be 'OPEN' and purchase order secondary status should be 'SCHEDULED' (score: 0.644)\n",
            "purchase order primary status should be 'CLOSED' and if {threshold} is given in the question, then total vendor short quantity should be lesser than or equal to the negative value of the given {threshold}. If {threshold} is not given then compare with zero. {threshold} is a non negative value (score: 0.626)\n",
            "purchase order primary status should be 'CLOSED' and if the question includes a threshold, minimum value, then total vendor short quantity should be greater than or equal to that value. If no such value is mentioned compare with 0. threshold is a non negative value. Do not use TOTAL_RECEIVED_CASES or any other fields in the filtering logic. (score: 0.619)\n",
            "\n",
            "\n",
            "\u001b[91mFAILED\u001b[0m\n",
            "Expected: anticipated receipt date should be before than today. purchase order type should be 'REGULAR' and purchase order primary status should be 'OPEN' and purchase order secondary status either 'SCHEDULED' OR 'ACCEPTED'\n",
            "Actual: anticipated receipt date should be before than today. purchase order type should be 'REGULAR' and purchase order primary status should be 'OPEN' and purchase order secondary status either 'SCHEDULED' OR 'ACCEPTED' (score: 0.693)\n",
            "date of scheduled purchase order receipt timestamp should be before today's date. purchase order primary status should be 'OPEN' and purchase order secondary status should be 'SCHEDULED' (score: 0.632)\n",
            "(anticipated receipt date + given time interval or date) should be older than today date and purchase order primary status equals to 'OPEN' and purchase order secondary status not equals to 'PARTIALLY_RECEIVED' (score: 0.614)\n",
            "\n",
            "\n",
            "\u001b[91mFAILED\u001b[0m\n",
            "Expected: anticipated receipt date should be before than today. purchase order type should be 'REGULAR' and purchase order primary status should be 'OPEN' and purchase order secondary status either 'SCHEDULED' OR 'ACCEPTED'\n",
            "Actual: (anticipated receipt date + given time interval or date) should be older than today date and purchase order primary status equals to 'OPEN' and purchase order secondary status not equals to 'PARTIALLY_RECEIVED' (score: 0.747)\n",
            "anticipated receipt date should be before than today. purchase order type should be 'REGULAR' and purchase order primary status should be 'OPEN' and purchase order secondary status either 'SCHEDULED' OR 'ACCEPTED' (score: 0.736)\n",
            "date of scheduled purchase order receipt timestamp should be before today's date. purchase order primary status should be 'OPEN' and purchase order secondary status should be 'SCHEDULED' (score: 0.696)\n",
            "purchase order primary status should be 'CLOSED' and if {threshold} is given in the question, then total vendor short quantity should be lesser than or equal to the negative value of the given {threshold}. If {threshold} is not given then compare with zero. {threshold} is a non negative value (score: 0.689)\n",
            "purchase order primary status should be 'CLOSED' and if the question includes a threshold, minimum value, then total vendor short quantity should be greater than or equal to that value. If no such value is mentioned compare with 0. threshold is a non negative value. Do not use TOTAL_RECEIVED_CASES or any other fields in the filtering logic. (score: 0.684)\n",
            "\n",
            "\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "CancelledError",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mCancelledError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-230-81443f992f0c>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mquery_with_category\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mqueries\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0;32mawait\u001b[0m \u001b[0mcheck_query\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquery_with_category\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-228-09aada2eeca1>\u001b[0m in \u001b[0;36mcheck_query\u001b[0;34m(query_with_category)\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0mquery\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mquery_with_category\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mcategory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mquery_with_category\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mbusiness_rule\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mawait\u001b[0m \u001b[0mget_business_rule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mquery\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mbusiness_rules\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcategory\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mbusiness_rule\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-225-b0a0e43cb75a>\u001b[0m in \u001b[0;36mget_business_rule\u001b[0;34m(message)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32masync\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mget_business_rule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m   \u001b[0membedded_question\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mawait\u001b[0m \u001b[0mget_embeddings_for_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m   return bq_connector.retrieve_matches(\n",
            "\u001b[0;32m<ipython-input-223-10a18f4d63b7>\u001b[0m in \u001b[0;36mget_embeddings_for_text\u001b[0;34m(text)\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;34m\"\"\"Get Text Embeddings from Model\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0membedder\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mEmbedderAgent\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0membeddings_model\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'text-embedding-004'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0membeddings\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mawait\u001b[0m \u001b[0membedder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0membeddings\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-215-802c89f66207>\u001b[0m in \u001b[0;36mcreate\u001b[0;34m(self, questions, task, dimensionality)\u001b[0m\n\u001b[1;32m     27\u001b[0m         \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mTextEmbeddingInput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtask\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mtext\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mquestions\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m         \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m\"output_dimensionality\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mdimensionality\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m         \u001b[0membeddings\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mawait\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_embeddings_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0membedding\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0membedding\u001b[0m \u001b[0;32min\u001b[0m \u001b[0membeddings\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/vertexai/language_models/_language_models.py\u001b[0m in \u001b[0;36mget_embeddings_async\u001b[0;34m(self, texts, auto_truncate, output_dimensionality)\u001b[0m\n\u001b[1;32m   2225\u001b[0m         )\n\u001b[1;32m   2226\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2227\u001b[0;31m         prediction_response = await self._endpoint.predict_async(\n\u001b[0m\u001b[1;32m   2228\u001b[0m             \u001b[0minstances\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mprediction_request\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minstances\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2229\u001b[0m             \u001b[0mparameters\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mprediction_request\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/google/cloud/aiplatform/models.py\u001b[0m in \u001b[0;36mpredict_async\u001b[0;34m(self, instances, parameters, timeout)\u001b[0m\n\u001b[1;32m   2547\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2548\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2549\u001b[0;31m         prediction_response = await self._prediction_async_client.predict(\n\u001b[0m\u001b[1;32m   2550\u001b[0m             \u001b[0mendpoint\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_gca_resource\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2551\u001b[0m             \u001b[0minstances\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minstances\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/google/cloud/aiplatform_v1/services/prediction_service/async_client.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, request, endpoint, instances, parameters, retry, timeout, metadata)\u001b[0m\n\u001b[1;32m    449\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    450\u001b[0m         \u001b[0;31m# Send the request.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 451\u001b[0;31m         response = await rpc(\n\u001b[0m\u001b[1;32m    452\u001b[0m             \u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    453\u001b[0m             \u001b[0mretry\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mretry\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/google/api_core/grpc_helpers_async.py\u001b[0m in \u001b[0;36m__await__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     83\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__await__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mIterator\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mP\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     84\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 85\u001b[0;31m             \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32myield\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__await__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     86\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mgrpc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mRpcError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mrpc_error\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/grpc/aio/_interceptor.py\u001b[0m in \u001b[0;36m__await__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    469\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0m_InterceptedUnaryResponseMixin\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    470\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__await__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 471\u001b[0;31m         \u001b[0mcall\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32myield\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_interceptors_task\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__await__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    472\u001b[0m         \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32myield\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mcall\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__await__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    473\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mresponse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mCancelledError\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ofAeID5eye-r"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}